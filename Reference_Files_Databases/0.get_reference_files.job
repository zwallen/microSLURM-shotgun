#!/bin/bash
#
#SBATCH --partition=amd-hdr100
#SBATCH --job-name=get_reference_files
#SBATCH --output=0.get_reference_files.log
#SBATCH --ntasks=1
#SBATCH --time=50:00:00
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=32000
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=wallenz@uab.edu

### Host reference genomes for decontaminating sequence files ###
# human reference genome
wget "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.28_GRCh38.p13/GCA_000001405.28_GRCh38.p13_genomic.fna.gz"
gunzip GCA_000001405.28_GRCh38.p13_genomic.fna.gz

# mouse reference genome
wget "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/635/GCA_000001635.9_GRCm39/GCA_000001635.9_GRCm39_genomic.fna.gz"
gunzip GCA_000001635.9_GRCm39_genomic.fna.gz

### HUMAnN reference databases and mapping files ###
# ChocoPhlAn database
wget "http://huttenhower.sph.harvard.edu/humann_data/chocophlan/full_chocophlan.v296_201901b.tar.gz"
tar -xvzf full_chocophlan.v296_201901b.tar.gz
mkdir full_chocophlan.v296_201901b
mv g__* full_chocophlan.v296_201901b/
rm full_chocophlan.v296_201901b.tar.gz

# UniRef90 database
wget "http://huttenhower.sph.harvard.edu/humann_data/uniprot/uniref_annotated/uniref90_annotated_v201901b_full.tar.gz"
tar -xvzf uniref90_annotated_v201901b_full.tar.gz
mkdir uniref90_annotated_v201901b_full
mv uniref90_201901b_full.dmnd uniref90_annotated_v201901b_full//
rm uniref90_annotated_v201901b_full.tar.gz

# mapping files
wget "http://huttenhower.sph.harvard.edu/humann_data/full_mapping_v201901b.tar.gz"
tar -xvzf full_mapping_v201901b.tar.gz
wget "https://huttenhower.sph.harvard.edu/humann_data/map_uniprot_uniref.tsv.gz"
mkdir full_mapping_v201901b
mv map_* full_mapping_v201901b/
mv *tol-lca.dat.bz2 full_mapping_v201901b/
rm full_mapping_v201901b.tar.gz

### Kraken2/Bracken database ###
# standard Kraken2 database with 50, 75, 100, 150, 200, 250, and 300-mers files for Bracken
DBNAME=k2_standard_20220926
mkdir ${DBNAME}
wget "https://genome-idx.s3.amazonaws.com/kraken/${DBNAME}.tar.gz" # this is a large file, may take a while to download
mv ${DBNAME}.tar.gz ${DBNAME}/
tar -xzf ${DBNAME}/${DBNAME}.tar.gz # again, large file, may take a while to decompress
rm ${DBNAME}/${DBNAME}.tar.gz

echo " *** Reference databases for running SLURM_Shotgun_Metagenomic_Pipeline.sh have been downloaded ***"
